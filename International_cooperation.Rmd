---
title: "International cooperation"
author: "L.-Y. M."
date: "2024-02-14"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
library("tidyverse")
library("ggExtra") # for marginal plot
library("scattermore")
library("cowplot")
# library("VGAM")
library("gganimate")
```

## R Markdown

Reference: Lin, Y., Frey, C. B., & Wu, L. (2023). Remote collaboration fuses fewer breakthrough ideas. Nature, 623(7989), 987â€“991. <https://doi.org/10.1038/s41586-023-06767-1>

The raw date used in this project can be found in [here](https://www.dropbox.com/scl/fi/16zx8y4he5l20iaahf3m8/RemoteTeam_DataForMainFigrues.zip?rlkey=c59tog9qecn61fvuzo9o0aczu&e=2&dl=0). Or using the provided link in the paper which is <https://lyl010.github.io>. You need click "Code & Data" and then click "Data" to navigate the data page. Please download the data, which is a file named "raw data.zip", and unzip it in the same directory as this file.

```{r data input, echo = FALSE}
dataset1 <- read_csv("raw data/Paperid_Remoteness_Authors_Teamroles.csv")
city_latlong <- read_csv("raw data/ScienceCityLatLong.csv")
paperid_year <- read_delim("raw data/Paperid_Year_Discipline_Teamsize_Distance_Dscore.txt", col_names =
                             c("Paperid","Year","Discipline","Teamsize","Distance","Dscore"), delim = "\t")
dataset2 <- read_delim("raw data/ScienceDisruptionCityEdges.txt", col_names = 
                         c("Connection","color","main_city","D_score1","D_score2"), delim = "\t")
dataset5 <- read_csv("raw data/Paperid_Remoteness_Authors_Teamroles.csv")
```

## Prepare data

You can also embed plots, for example:

```{r data reshaping}
connection_data <- dataset2 %>% 
  unite(D_score,c("D_score1","D_score2"),sep = ",")

# we use the same way to classify the discipline as the original paper
science_and_engineering = c("geology","medicine","mathematics","physics","materials science",
                            "biology","chemistry","engineering","computer science","geography",
                            "environmental science")
social_sciences <- c("political science","business","economics","psychology","sociology")
art_and_humanity <- c("history","art","philosophy")
# the definition above can be found in the code of the original paper

df <- bind_rows(
  data.frame(Discipline = science_and_engineering, fields = "science_and_engineering"),
  data.frame(Discipline = social_sciences, fields = "social_sciences"),
  data.frame(Discipline = art_and_humanity, fields = "art_and_humanity")
)

paperid_year <- left_join(paperid_year, df, by = "Discipline")
```

```{r top1 percent}
top_paper <- paperid_year %>% 
  filter(Dscore > 0.2)
# ds: Dscore; di: Distance; hist: histogram
ds_hist <- ggplot(top_paper, aes(x = Dscore))
ds_hist + geom_histogram()

# n0: no 0 (distance)
ds_n0_hist <- top_paper %>% 
  filter(Distance > 0) %>%
  ggplot(aes(x = Dscore))
ds_n0_hist + geom_histogram()

di_hist <- ggplot(top_paper, aes(x = Distance))
di_hist + geom_histogram()

di_n0_hist <- top_paper %>% 
  filter(Distance > 0) %>%
  ggplot(aes(x = Distance))
di_n0_hist + geom_histogram()

# d_d: distance vs Dscore
d_d <- ggplot(top_paper, aes(x = Distance, y = Dscore, color = Year)) +
  geom_point(alpha = 0.1) +
  theme_cowplot() +
  theme(legend.position = "left")
ggMarginal(d_d, type = "histogram")

d_d_n0 <- ggplot(top_paper %>% filter(Distance > 0), aes(x = Distance, y = Dscore, color = Year, shape = fields)) +
  geom_point(alpha = 0.1) +
  theme_cowplot() +
  theme(legend.position = "left")
ggMarginal(d_d_n0, type = "histogram")
```

It is obvious that there are several value of Dscore are extremely frequent. It is probably due to the few cited papers. Let's filter out those papers and replot the graph.

```{r frequency of Dscore}
# calculate the frequency of each Dscore value
frequency_Dscore <- top_paper %>% 
  group_by(Dscore) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n))

# filter out the few cited papers (extremely frequent Dscore)
# ex_lc: exclude the few cited papers
ex_fc <- left_join(top_paper, frequency_Dscore, by = "Dscore") %>% 
  filter(n < 1000) # that is an arbitrary threshold

d_d_n0_ex_fc <- ex_lc %>% 
  filter(Distance > 0) %>%
  ggplot(aes(x = Distance, y = Dscore, color = Year)) + 
  geom_point(alpha = 0.1) + theme_cowplot() + theme(legend.position = "left")
ggMarginal(d_d_n0_ex_fc, type = "histogram")
```

```{r log scale}
d_d_n0_log <- d_d_n0 + scale_x_continuous(trans = 'log10') + # Log scale for x-axis
  scale_y_continuous(trans = 'log10') +# Log scale for y-axis
  theme_cowplot() +
  theme(legend.position = "left")
ggMarginal(d_d_n0_log, type = "histogram")
```

Now we focus on the data of local collaboration, that is the distance is 0.

```{r distribution of Dscore in local}
# l: local
ds_hist_l_ex_fc <- ex_fc %>% 
  filter(Distance == 0) %>%
  ggplot(aes(x = Dscore))
ds_hist_l_ex_fc + geom_histogram()
```

The resason why distance is extremly right-skewed might be that those papers are demestic collaboration. It is impossible to investigate the affect of demestic / international collaboration on the Dscore due to the data lack of that information. However, we can use distance as a proxy of demestic / international collaboration. According SJR, Germany is top 4 country which published most paper and has a medium territory area, that is 357,021 km2. Let's assume that it is a circle, then the radius is 337 km. We can use this value as a threshold to distinguish demestic and international collaboration.

```{r data of demestic collabo}
# deme: demestic
d_d_deme_ex_fc <- ex_fc %>%
  filter(Distance < 337) %>%
  ggplot(aes(x = Distance, y = Dscore, color = Year)) +
  geom_point(alpha = 0.1) + theme_cowplot() +
  theme(legend.position = "left")
ggMarginal(d_d_deme_ex_fc, type = "histogram")

d_d_deme_n0_ex_fc <- ex_fc %>%
  filter(Distance < 337) %>%
  filter(Distance > 0) %>%
  ggplot(aes(x = Distance, y = Dscore, color = Year)) +
  geom_point(alpha = 0.1) + theme_cowplot() + 
  theme(legend.position = "left")
ggMarginal(d_d_deme_n0_ex_fc, type = "histogram")
```

```{r data of international collaboration}
d_d_inte <- ggplot(top_paper %>% filter(Distance > 700), aes(x = Distance, y = Dscore, color = Year, shape = fields)) +
  geom_point(alpha = 0.1) + theme_cowplot() +
  theme(legend.position = "left")
ggMarginal(d_d_inte, type = "histogram")
```
The data of international collaboration is also right-skewed. It is probably due to the convenience of international collaboration in the Europe. Let's consider the data of intercontinental collaboration in the next step. In top 10 countries which published most papers, the most close countries pair (intercontinental) are Australia and Japan. The distance between them is 6,766 km. Let's assume that it is a threshold to distinguish intercontinental collaboration.

```{r data of intercontinental collaboration}
d_d_interconti_ex_fc <- ex_fc %>%
  filter(Distance > 6766) %>%
  ggplot(aes(x = Distance, y = Dscore, color = Year)) +
  geom_point(alpha = 0.1) + theme_cowplot() +
  theme(legend.position = "left")
ggMarginal(d_d_interconti_ex_fc, type = "histogram")
```

For the most papers, which Dscore concentrated in the range of -0.2 to 0.2.

```{r data of 99 percent}
most_paper <- paperid_year %>% 
  filter(Dscore < 0.2) %>%
  filter(Dscore > -0.2)
# ds: Dscore; di: Distance; hist: histogram
ds_hist_most <- ggplot(most_paper, aes(x = Dscore))
ds_hist_most + geom_histogram()

# n0: no 0 (distance)
ds_n0_hist_most <- most_paper %>% 
  filter(Distance > 0) %>%
  ggplot(aes(x = Dscore))
ds_n0_hist_most + geom_histogram()

di_hist_most <- ggplot(most_paper, aes(x = Distance))
di_hist_most + geom_histogram()

di_n0_hist_most <- most_paper %>% 
  filter(Distance > 0) %>%
  ggplot(aes(x = Distance))
di_n0_hist_most + geom_histogram()

# d_d: distance vs Dscore
d_d_most <- ggplot(most_paper, aes(x = Distance, y = Dscore, color = Year)) +
  geom_scattermore(alpha = 0.1) # using scattermore for speed; otherwise, it will take forever
d_d_most + theme_cowplot()
ggMarginal(d_d_most, type = "histogram")
```
Let's see all the data in one graph.

```{r all data}
d_d_all <- ggplot(paperid_year, aes(x = Distance, y = Dscore, color = Year)) +
  geom_scattermore(alpha = 0.05) + theme_cowplot()
d_d_all

anim_all <- paperid_year %>% 
  ggplot(aes(x = Distance, y = Dscore, color = Year), frame(Year)) +
  geom_scattermore() +
  
anim_all
# ggMarginal(d_d_all, type = "histogram")

d_d_all_SE <- paperid_year %>%
  filter(fields == "science_and_engineering") %>%
  ggplot(aes(x = Distance, y = Dscore, color = Year)) +
  geom_scattermore(alpha = 0.05) + theme_cowplot() +
  scale_color_gradient(low="black", high="#619CFF") +
  title("Science and Engineering")
d_d_all_SE

d_d_all_SS <- paperid_year %>%
  filter(fields == "social_sciences") %>%
  ggplot(aes(x = Distance, y = Dscore, color = Year)) +
  geom_scattermore(alpha = 0.05) + theme_cowplot() +
  scale_color_gradient(low="black", high="#00BA38") +
  title("Social Sciences")
d_d_all_SS

d_d_all_AH <- paperid_year %>%
  filter(fields == "art_and_humanity") %>%
  ggplot(aes(x = Distance, y = Dscore, color = Year)) +
  geom_scattermore(alpha = 0.05) + theme_cowplot() +
  scale_color_gradient(low="black", high="#F8766D") +
  title("Art and Humanity")
d_d_all_AH

```
One potential explanation for the distribution of the data is the file-drawer problem. The file-drawer problem is a problem in meta-analysis in which studies with null results are less likely to be published than studies with significant results. It is possible that the data is biased because the less breakthrough results are less likely to be published. Let's see the distribution of the data by categories.
```{r analysis by categories}
breaks_distacne <- c(-1, 5000, 10000, 15000, 20000)
breaks_dscore <- c(-1, -0.5, 0, 0.5, 1)
data_classified <- paperid_year %>%
  mutate(Distance = cut(Distance, breaks = breaks_distacne, labels = c("0-5000", "5000-10000", "10000-15000", "15000-20000")),
         Dscore = cut(Dscore, breaks = breaks_dscore, labels = c("(-1, -0.5]", "(-0.5, 0]", "(0, 0.5]", "(0.5, 1]")))
table(data_classified$Distance, data_classified$Dscore) %>% 
prop.table(margin = 1)
d_d_all_classified <- ggplot(data_classified, aes(x = Distance, y = Dscore, color = Year)) +
```
Most papers are located in the range of 0 to 1000 km. If we weithed each data point by the number of papers in the same distance, we can see the distribution of the data more clearly.

```{r weighted data}
frequency_Distance_all <- paperid_year %>%
  group_by(Distance) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n))

# weighted distance
alldata_with_frequency <- left_join(paperid_year, frequency_Distance_all, by = "Distance")

# distance weighted
d_d_all_w <- ggplot(alldata_with_frequency, aes(x = Distance, y = Dscore, color = Year, alpha = 0.5/n)) +
  geom_scattermore() + theme_cowplot()
d_d_all_w
```

If you notice the missing data is as much as 1/3 of the total data. You may wonder how those missing data distributed, and how the missing data affect the result. 
Let's see the missing data.

```{r missing data}
missing_data <- paperid_year %>%
  filter(is.na(Dscore))

di_hist_miss <- ggplot(missing_data, aes(x = Distance))
di_hist_miss + geom_histogram()

year_hist_miss <- ggplot(missing_data, aes(x = Year))
year_hist_miss + geom_histogram()

# visualizing the missing data
breaks_distacne_fine <- c(-1, 0.5, 1000, 5000, 10000, 15000, 20000)
breaks_year <- seq(from = 1960, to = 2020, by = 5)
missing_data_cat <- paperid_year %>%
  select(Distance, Year, Dscore) %>%
  mutate(Distance = cut(Distance, breaks = breaks_distacne_fine, labels = c("0", "1", "1000", "5000", "10000", "15000")),
         Year = cut(Year, breaks = breaks_year, labels = c("1960", "1965", "1970", "1975", "1980", "1985", "1990", "1995", "2000", "2005", "2010", "2015"))) %>% 
  group_by(Distance, Year) %>%
  summarise(N = n(), n = sum(is.na(Dscore)), .groups = 'drop') %>% 
  ungroup() %>% 
  mutate(missing_rate = n/N)

# y_d: Year vs Distance
y_d_missing <- missing_data_cat %>% 
  ggplot(aes(x = Distance, y = Year, fill = missing_rate,
             label = round(missing_rate, 2))) +
  geom_tile() +
  geom_text(color = "black") +  # Add text labels
  scale_fill_gradient(low = "white", high = "red") +
  labs(title = "Heatmap of missing data", fill = "Missing Rate") +
  theme_cowplot()
y_d_missing
```
So in the row of 2015 which including data from 2015 to 2020, the missing rate is the highest. It is probably due to that 2020 is the year of data collection. Papers published in 2020 and a few years before are less likely to be cited.

Now, let's reanalyze the data using the regression model with Laplace prior.

```{r linear regression}
full_model <- vglm(Dscore ~ Distance + fields + Year, family = laplace, data = paperid_year)
# check which parameters can have priors
get_prior(Dscore ~ Distance + fields + Year, data = paperid_year)
# set the prior for the regression
prior <- set_prior("normal(0, 1)", class = "b") +
  set_prior("normal(0, 1)", class = "Intercept") +
  set_prior("cauchy(0, 1)", class = "sd")
# regression with Laplace distribution prior
linear_regression <- brm(Dscore ~ Distance + fields, data = paperid_year)

```
